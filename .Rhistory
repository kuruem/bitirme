library(stringr)
install.packages("utf8")
install.packages("gutenbergr")
library(gutenbergr)
sherlock_raw <- gutenberg_download(1661)
View(sherlock_raw)
View(sherlock_raw)
sherlock <- sherlock_raw %>%
mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%
fill(story) %>%
filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%
mutate(story = factor(story, levels = unique(story)))
sherlock <- sherlock_raw %>%mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%fill(story) %>%filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%mutate(story = factor(story, levels = unique(story)))
install.packages("tidyverse")
library(tidyverse)
sherlock_raw <- gutenberg_download(1661)
sherlock <- sherlock_raw %>%mutate(story = ifelse(str_detect(text, "ADVENTURE"),
text,
NA)) %>%fill(story) %>%filter(story != "THE ADVENTURES OF SHERLOCK HOLMES") %>%mutate(story = factor(story, levels = unique(story)))
sherlock
View(sherlock)
View(sherlock)
library(tidytext)
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
filter(word != "holmes")
tidy_sherlock %>%
count(word, sort = TRUE)
install.packages("tidytext")
library(tidytext)
tidy_sherlock <- sherlock %>%
mutate(line = row_number()) %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
filter(word != "holmes")
tidy_sherlock %>%
count(word, sort = TRUE)
View(tidy_sherlock)
View(tidy_sherlock)
install.packages("drlib")
install.packages("drlib")
library(drlib)
install.packages("quanteda")
install.packages("stm")
library(quanteda)
library(stm)
sherlock_dfm <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_dfm(story, word, n)
sherlock_sparse <- tidy_sherlock %>%
count(story, word, sort = TRUE) %>%
cast_sparse(story, word, n)
View(sherlock_sparse)
View(sherlock_sparse)
topic_model <- stm(sherlock_dfm, K = 6,
verbose = FALSE, init.type = "Spectral")
library(stm)
install.packages("stringr")
install.packages("stringr")
install.packages("text2vec")
library(stringr)
library(text2vec)
data("movie_review")
library(text2vec)
install.packages('text2vec')
install.packages('RcppParallel')
library("Rcpp", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
install.packages('RcppParallel')
library("parallel", lib.loc="/usr/lib/R/library")
install.packages('text2vec')
install.packages('RcppParallel')
install.packages('text2vec')
install.packages('Rcpp11')
install.packages('text2vec')
library("Rcpp11", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
install.packages('text2vec')
install.packages('RcppParallel')
detach("package:Rcpp", unload=TRUE)
library("Rcpp", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
install.packages('text2vec')
install.packages(c("Rcpp", "RcppParallel", "digest"), type = "source")
install.packages(c("text2vec"), type = "source")
install.packages(c("Rcpp", "RcppParallel", "digest"), type = "source")
library(stringr)
library(text2vec)
install.packages(c("text2vec"), type = "source")
install.packages(c("Rcpp", "RcppParallel", "digest"), type = "source")
install.packages(c("Rcpp", "RcppParallel", "digest"), type = "source")
install.packages(c("text2vec"), type = "source")
library("parallel", lib.loc="/usr/lib/R/library")
install.packages('textmineR')
install.packages('RcppParallel')
devtools::install_github("RcppCore/RcppParallel")
install.packages(c('devtools','curl'))
library('devtools')
devtools::install_github("RcppCore/RcppParallel")
library('RcppParallel')
install.packages('text2vec')
library("text2vec", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
library(stringr)
library(text2vec)
data("movie_review")
movie_review_train = movie_review[1:700, ]
movie_review_test = movie_review[701:1000, ]
View(movie_review)
movie_review_train$review = prep_fun(movie_review_train$review)
prep_fun = function(x) {
x %>%
# make text lower case
str_to_lower %>%
# remove non-alphanumeric symbols
str_replace_all("[^[:alpha:]]", " ") %>%
# collapse multiple spaces
str_replace_all("\\s+", " ")
}
movie_review_train$review = prep_fun(movie_review_train$review)
View(movie_review_train)
View(movie_review_test)
it = itoken(movie_review_train$review, progressbar = FALSE)
v = create_vocabulary(it) %>%
prune_vocabulary(doc_proportion_max = 0.1, term_count_min = 5)
vectorizer = vocab_vectorizer(v)
dtm = create_dtm(it, vectorizer)
tfidf = TfIdf$new()
lsa = LSA$new(n_topics = 10)
doc_embeddings = dtm %>%
fit_transform(tfidf) %>%
fit_transform(lsa)
View(doc_embeddings)
new_data = movie_review_test
new_doc_embeddings =
new_data$review %>%
itoken(preprocessor = prep_fun, progressbar = FALSE) %>%
create_dtm(vectorizer) %>%
# apply exaxtly same scaling wcich was used in train data
transform(tfidf) %>%
# embed into same space as was in train data
transform(lsa)
dim(new_doc_embeddings)
tokens = movie_review$review[1:4000] %>%
tolower %>%
word_tokenizer
it = itoken(tokens, ids = movie_review$id[1:4000], progressbar = FALSE)
v = create_vocabulary(it) %>%
prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.2)
vectorizer = vocab_vectorizer(v)
dtm = create_dtm(it, vectorizer, type = "dgTMatrix")
lda_model = LDA$new(n_topics = 10, doc_topic_prior = 0.1, topic_word_prior = 0.01)
doc_topic_distr =
lda_model$fit_transform(x = dtm, n_iter = 1000,
convergence_tol = 0.001, n_check_convergence = 25,
progressbar = FALSE)
barplot(doc_topic_distr[1, ], xlab = "topic",
ylab = "proportion", ylim = c(0, 1),
names.arg = 1:ncol(doc_topic_distr))
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 1)
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 0.2)
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), shell)
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), "shell")
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 0.2, "shell")
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 0.2)
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 0.2, method = c("auto", "shell", "radix"))
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 1)
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 1, method = c("shell"))
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L),  method = c("shell"))
lda_model$get_top_words(n = 10, topic_number = c(1L, 5L, 10L), lambda = 1)
new_dtm = itoken(movie_review$review[4001:5000], tolower, word_tokenizer, ids = movie_review$id[4001:5000]) %>%
create_dtm(vectorizer, type = "dgTMatrix")
new_doc_topic_distr = lda_model$transform(new_dtm)
perplexity(new_dtm, topic_word_distribution = lda_model$topic_word_distribution, doc_topic_distribution = new_doc_topic_distr)
lda_model$plot()
install.packages('LDAvis')
pwd
setwd("/home/emre/Masaüstü/bitirme/hello/repo")
freqs<-read.csv('freqs.csv')
head(freqs)
freqs<-read.csv('freqs.csv')
head(freqs)
boxplot(freqs$freqs)
freqs<-read.csv('freqs.csv')
boxplot(freqs$freqs)
boxplot.default(freqs$freqs)
summary(freqs)
freqs<-read.csv('freqs.csv')
boxplot.default(freqs$freqs)
summary(freqs)
freqs<-read.csv('freqs.csv')
boxplot.default(freqs$freqs)
freqs<-read.csv('freqs.csv')
summary(freqs)
freqs<-read.csv('freqs.csv')
boxplot.default(freqs$freqs)
summary(freqs)
freqs<-read.csv('freqs.csv')
summary(freqs)
boxplot.default(freqs$freqs)
boxplot.default(freqs$freq)
